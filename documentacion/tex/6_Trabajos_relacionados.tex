\capitulo{6}{Trabajos relacionados}

La detección de exoplanetas mediante el método del tránsito es un área en expansión. No es solo que los datos de Kepler aún no estén totalmente explotados, sino que a ellos hemos de sumarle los datos que suministra el telescopio TESS y, en breve, los del telescopio James Webb. Es, además, un problema abierto, donde se siguen buscando activamente nuevas soluciones ya sea trabajando con nuevos y diferentes datos o usando técnicas diferentes.

\section{Kaggle}

La forma más rápida de encontrar soluciones alternativas es recurrir al origen de los datos, la página web de Kaggle \cite{Kaggle-exoplanet}, donde podemos encontrar 46 \textit{kernels}, que es el nombre que con el Kaggle denomina a los notebooks. Las técnicas usadas y los resultados obtenidos varían ampliamente, por lo que solamente vamos a comentar un par de ellos que presentan enfoques alternativos o buenos resultados.

\subsection{CNN - based on Google/Kepler approach \cite{Kaggle-kernel-CNN-Google}} 

El autor de este kernel sigue algunos de los pasos comentados en el paper \textit{Identifying Exoplanets with Deep Learning} \cite{2018AJ....155...94S}, publicado por Google en colaboración con la NASA, en el que los autores utilizan otro conjunto de datos de Kepler para resolver el mismo problema.

En cuanto a la arquitectura de este modelo es bastante simple, consistiendo en varios bloques de capas convolucionales seguidas de pooling y dropout. La parte más interesante de este trabajo está en el procesado de los datos. El autor opta primero por duplicar las instancias positivas invirtiéndolas en el tiempo. Una vez creadas las instancias positivas, añade algunas negativas hasta llegar a un tamaño total de 1000 instancias, alegando que en otros modelos que ha probado, el hecho de utilizar todas las instancias del dataset no suponía una mejoría en los resultados.   

\subsection{Exoplanet Classifier (CNN + RNN) \cite{Kaggle-kernel-Exoplanet-Classifier}}

Este es un kernel particularmente interesante ya presenta una arquitectura compleja, una nueva técnica en el procesado de datos y obtiene muy buenos resultados. Se trata de un modelo de \textit{ensemble}, una composición de varios modelos, concretamente \textit{stacking}, donde la salida de un modelo sirve de entrada a otro. En este caso, el primero de los modelos consiste en una red LSTM de cuatro capas con dropout, similar a la usada por nuestros modelos. El resultado de dicha red sirve para alimentar una red convolucional unidimensional. Esta está formada por cuatro bloques, cada uno conteniendo una capa de convolución, seguida de una capa de pooling y otra de normalización. Finalmente, el modelo cuenta con dos capas totalmente conectadas que proporcionan la salida de la red.

A la hora de procesar los datos, afronta el desbalanceo del dataset generando \textit{mini batches} de 32 elementos, con igual número de elementos en cada clase. Para evitar la sobre exposición de la red a los mismos casos positivos una y otra vez, genera nuevas instancias a través de la rotación de los datos en el tiempo. Esto es, para cada una de las instancias del mini batch genera un número aleatorio entre 0 y la longitud de los datos, desplazándolos luego hacia la derecha ese número de posiciones. 

Probado con el dataset de test, el área bajo la curva obtenida es de 1, la sensibilidad igualmente es de 1 y la especificidad se queda en 0.99; unos resultados impresionantes. 

\subsection{Exoplanet-Hunting-Recall-1.0-Precision-0.55 \cite{Kaggle-kernel-Exoplanet-Hunting}} 

Este kernel usa un procesado de datos muy similar al usado durante este proyecto, normalización, filtro gaussiano y análisis de frecuencia mediante Fourier, difiriendo en el modelo de red, usando en este caso máquinas de vectores soporte y obteniendo buenos resultados.
